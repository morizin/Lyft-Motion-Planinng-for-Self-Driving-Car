{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:27:15.679585Z",
     "iopub.status.busy": "2020-10-24T02:27:15.678656Z",
     "iopub.status.idle": "2020-10-24T02:27:26.592075Z",
     "shell.execute_reply": "2020-10-24T02:27:26.591442Z"
    },
    "id": "zu0gZ5x1al6_",
    "outputId": "34601fc1-2b94-4681-db0d-40f8a657f230",
    "papermill": {
     "duration": 10.934762,
     "end_time": "2020-10-24T02:27:26.592221",
     "exception": false,
     "start_time": "2020-10-24T02:27:15.657459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\r\n",
      "  Downloading timm-0.2.1-py3-none-any.whl (225 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 225 kB 404 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.7.0)\r\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.6.0)\r\n",
      "Requirement already satisfied: numpy in /kaggle/usr/lib/lyft_l5kit_unofficial_fix (from torchvision->timm) (1.19.2)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.0.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:27:26.643753Z",
     "iopub.status.busy": "2020-10-24T02:27:26.641302Z",
     "iopub.status.idle": "2020-10-24T02:27:30.921205Z",
     "shell.execute_reply": "2020-10-24T02:27:30.920479Z"
    },
    "id": "P0vVpA0tSBXD",
    "papermill": {
     "duration": 4.308676,
     "end_time": "2020-10-24T02:27:30.921345",
     "exception": false,
     "start_time": "2020-10-24T02:27:26.612669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "#from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "from tqdm import tqdm\n",
    "\n",
    "import l5kit\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import timm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:27:30.994060Z",
     "iopub.status.busy": "2020-10-24T02:27:30.993002Z",
     "iopub.status.idle": "2020-10-24T02:27:31.000084Z",
     "shell.execute_reply": "2020-10-24T02:27:31.000895Z"
    },
    "id": "SbO2heE0BCjX",
    "outputId": "47bd19b6-6a77-487f-e015-b34681cf7c47",
    "papermill": {
     "duration": 0.041905,
     "end_time": "2020-10-24T02:27:31.001060",
     "exception": false,
     "start_time": "2020-10-24T02:27:30.959155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l5kit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:27:31.066146Z",
     "iopub.status.busy": "2020-10-24T02:27:31.065072Z",
     "iopub.status.idle": "2020-10-24T02:27:31.072363Z",
     "shell.execute_reply": "2020-10-24T02:27:31.071871Z"
    },
    "id": "rZZcGhx4SCpG",
    "papermill": {
     "duration": 0.042437,
     "end_time": "2020-10-24T02:27:31.072459",
     "exception": false,
     "start_time": "2020-10-24T02:27:31.030022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:27:31.175302Z",
     "iopub.status.busy": "2020-10-24T02:27:31.174052Z",
     "iopub.status.idle": "2020-10-24T02:27:31.179765Z",
     "shell.execute_reply": "2020-10-24T02:27:31.178920Z"
    },
    "id": "ULvbCu1dSHyR",
    "papermill": {
     "duration": 0.062795,
     "end_time": "2020-10-24T02:27:31.179893",
     "exception": false,
     "start_time": "2020-10-24T02:27:31.117098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'data_path': \"../input/lyft-motion-prediction-autonomous-vehicles\",\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnest101',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1,\n",
    "        'model_name': \"lyft_res2net\",\n",
    "        'lr': 1e-3,\n",
    "        'weight_path': \"../input/res2net-lyft/lyft_res2net_1000.pth\",\n",
    "        'train': True,\n",
    "        'predict': False\n",
    "    },\n",
    "\n",
    "    'raster_params': {\n",
    "        'raster_size': [225, 225],\n",
    "        'pixel_size': [0.5, 0.5],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "\n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 96,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    }, \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    'train_params': {\n",
    "        'max_num_steps': 10000,\n",
    "        'checkpoint_every_n_steps': 500,\n",
    "        'image_coords':True\n",
    "    },\n",
    "    'test_params':{'image_coords':True}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:27:31.244196Z",
     "iopub.status.busy": "2020-10-24T02:27:31.242596Z",
     "iopub.status.idle": "2020-10-24T02:27:31.245177Z",
     "shell.execute_reply": "2020-10-24T02:27:31.245889Z"
    },
    "id": "Wk6vdMyWSQio",
    "papermill": {
     "duration": 0.037329,
     "end_time": "2020-10-24T02:27:31.246040",
     "exception": false,
     "start_time": "2020-10-24T02:27:31.208711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "DIR_INPUT = cfg[\"data_path\"]\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:27:31.312314Z",
     "iopub.status.busy": "2020-10-24T02:27:31.311430Z",
     "iopub.status.idle": "2020-10-24T02:28:58.713962Z",
     "shell.execute_reply": "2020-10-24T02:28:58.714766Z"
    },
    "id": "A59wxIGrSrOv",
    "outputId": "8a183001-7596-400a-8631-4e7b1c1fe259",
    "papermill": {
     "duration": 87.440204,
     "end_time": "2020-10-24T02:28:58.714932",
     "exception": false,
     "start_time": "2020-10-24T02:27:31.274728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================TRAIN DATA==================================\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "# ===== INIT TRAIN DATASET============================================================\n",
    "if cfg['model_params']['train']:\n",
    "  train_cfg = cfg[\"train_data_loader\"]\n",
    "  rasterizer = build_rasterizer(cfg, dm)\n",
    "  train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "  train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "  train_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"], batch_size=train_cfg[\"batch_size\"], \n",
    "                              num_workers=train_cfg[\"num_workers\"])\n",
    "  print(\"==================================TRAIN DATA==================================\")\n",
    "  print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:28:58.761689Z",
     "iopub.status.busy": "2020-10-24T02:28:58.761031Z",
     "iopub.status.idle": "2020-10-24T02:28:58.764833Z",
     "shell.execute_reply": "2020-10-24T02:28:58.765387Z"
    },
    "papermill": {
     "duration": 0.030301,
     "end_time": "2020-10-24T02:28:58.765512",
     "exception": false,
     "start_time": "2020-10-24T02:28:58.735211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg['train_params']['max_num_steps'] = len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:28:58.838807Z",
     "iopub.status.busy": "2020-10-24T02:28:58.837813Z",
     "iopub.status.idle": "2020-10-24T02:28:58.842231Z",
     "shell.execute_reply": "2020-10-24T02:28:58.843313Z"
    },
    "id": "Z-JJB6R9-v1Z",
    "papermill": {
     "duration": 0.051795,
     "end_time": "2020-10-24T02:28:58.843471",
     "exception": false,
     "start_time": "2020-10-24T02:28:58.791676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cfg['model_params']['predict']:\n",
    "#====== INIT TEST DATASET=============================================================\n",
    "    test_cfg = cfg[\"test_data_loader\"]\n",
    "    rasterizer = build_rasterizer(cfg, dm)\n",
    "    test_zarr = ChunkedDataset(dm.require(test_cfg[\"key\"])).open()\n",
    "    test_mask = np.load(f\"{DIR_INPUT}/scenes/mask.npz\")[\"arr_0\"]\n",
    "    test_dataset = AgentDataset(cfg, test_zarr, rasterizer, agents_mask=test_mask)\n",
    "    test_dataloader = DataLoader(test_dataset,shuffle=test_cfg[\"shuffle\"],batch_size=test_cfg[\"batch_size\"],\n",
    "                                 num_workers=test_cfg[\"num_workers\"])\n",
    "    print(\"==================================TEST DATA==================================\")\n",
    "    print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:28:58.924280Z",
     "iopub.status.busy": "2020-10-24T02:28:58.923320Z",
     "iopub.status.idle": "2020-10-24T02:28:58.946310Z",
     "shell.execute_reply": "2020-10-24T02:28:58.947479Z"
    },
    "id": "dOueIFbASvej",
    "papermill": {
     "duration": 0.069993,
     "end_time": "2020-10-24T02:28:58.947701",
     "exception": false,
     "start_time": "2020-10-24T02:28:58.877708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Original code from https://github.com/lyft/l5kit/blob/20ab033c01610d711c3d36e1963ecec86e8b85b6/l5kit/l5kit/evaluation/metrics.py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute a negative log-likelihood for the multi-modal scenario.\n",
    "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
    "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
    "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "    https://leimao.github.io/blog/LogSumExp/\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
    "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "    avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_single(\n",
    "    gt: Tensor, pred: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
    "    # create confidence (bs)x(mode=1)\n",
    "    batch_size, future_len, num_coords = pred.shape\n",
    "    confidences = pred.new_ones((batch_size, 1))\n",
    "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:28:59.037664Z",
     "iopub.status.busy": "2020-10-24T02:28:59.020217Z",
     "iopub.status.idle": "2020-10-24T02:28:59.041619Z",
     "shell.execute_reply": "2020-10-24T02:28:59.042691Z"
    },
    "id": "knO9HcHDS0YZ",
    "papermill": {
     "duration": 0.06571,
     "end_time": "2020-10-24T02:28:59.042852",
     "exception": false,
     "start_time": "2020-10-24T02:28:58.977142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LyftMultiModel(nn.Module):\n",
    "\n",
    "    def __init__(self,model_name, cfg: Dict, num_modes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(model_name)\n",
    "\n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.backbone.conv1.out_channels,\n",
    "            kernel_size=self.backbone.conv1.kernel_size,\n",
    "            stride=self.backbone.conv1.stride,\n",
    "            padding=self.backbone.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        # This is 512 for resnet18 and resnet34;\n",
    "        # And it is 2048 for the other resnets\n",
    "        \n",
    "        backbone_out_features = 2048\n",
    "\n",
    "        # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
    "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        num_targets = 2 * self.future_len\n",
    "\n",
    "        # You can add more layers here.\n",
    "        self.head = nn.Sequential(\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(in_features=backbone_out_features, out_features=4096),\n",
    "        )\n",
    "\n",
    "        self.num_preds = num_targets * num_modes\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        self.logit = nn.Linear(4096, out_features=self.num_preds + num_modes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.act1(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.global_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.head(x)\n",
    "        x = self.logit(x)\n",
    "\n",
    "        # pred (batch_size)x(modes)x(time)x(2D coords)\n",
    "        # confidences (batch_size)x(modes)\n",
    "        bs, _ = x.shape\n",
    "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
    "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
    "        assert confidences.shape == (bs, self.num_modes)\n",
    "        confidences = torch.softmax(confidences, dim=1)\n",
    "        return pred, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:28:59.148203Z",
     "iopub.status.busy": "2020-10-24T02:28:59.147361Z",
     "iopub.status.idle": "2020-10-24T02:28:59.153224Z",
     "shell.execute_reply": "2020-10-24T02:28:59.152044Z"
    },
    "papermill": {
     "duration": 0.080825,
     "end_time": "2020-10-24T02:28:59.153374",
     "exception": false,
     "start_time": "2020-10-24T02:28:59.072549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(data, model, device, criterion = pytorch_neg_multi_log_likelihood_batch):\n",
    "    inputs = data[\"image\"].to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].to(device)\n",
    "    targets = data[\"target_positions\"].to(device)\n",
    "    # Forward pass\n",
    "    preds, confidences = model(inputs)\n",
    "    loss = criterion(targets, preds, confidences, target_availabilities)\n",
    "    return loss, preds, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:28:59.228442Z",
     "iopub.status.busy": "2020-10-24T02:28:59.227420Z",
     "iopub.status.idle": "2020-10-24T02:28:59.234168Z",
     "shell.execute_reply": "2020-10-24T02:28:59.235066Z"
    },
    "id": "8--HNC78XT0V",
    "papermill": {
     "duration": 0.048181,
     "end_time": "2020-10-24T02:28:59.235221",
     "exception": false,
     "start_time": "2020-10-24T02:28:59.187040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def forward(data, model, device, criterion = pytorch_neg_multi_log_likelihood_batch):\\n    inputs = data[\"image\"].to(device)\\n    target_availabilities = data[\"target_availabilities\"].to(device)\\n    targets = data[\"target_positions\"].to(device)\\n    matrix = data[\"world_to_image\"].to(device)\\n    centroid = data[\"centroid\"].to(device)[:,None,:].to(torch.float)\\n\\n    # Forward pass\\n    outputs = model(inputs)\\n\\n    bs,tl,_ = targets.shape\\n    assert tl == cfg[\"model_params\"][\"future_num_frames\"]\\n\\n    if cfg[\\'train_params\\'][\\'image_coords\\']:\\n        targets = targets + centroid\\n        targets = torch.cat([targets,torch.ones((bs,tl,1)).to(device)], dim=2)\\n        targets = torch.matmul(matrix.to(torch.float), targets.transpose(1,2))\\n        targets = targets.transpose(1,2)[:,:,:2]\\n        bias = torch.tensor([56.25, 112.5])[None,None,:].to(device)\\n        targets = targets - bias\\n#     print(outputs)\\n    confidences, pred = outputs[1], outputs[0]\\n    pred = pred.view(bs, 3, tl, 2)\\n    assert confidences.shape == (bs, 3)\\n    confidences = torch.softmax(confidences, dim=1)\\n\\n    loss = criterion(targets, pred, confidences, target_availabilities)\\n    loss = torch.mean(loss)\\n\\n    if cfg[\\'train_params\\'][\\'image_coords\\']:\\n        matrix_inv = torch.inverse(matrix)\\n        pred = pred + bias[:,None,:,:]\\n        pred = torch.cat([pred,torch.ones((bs,3,tl,1)).to(device)], dim=3)\\n        pred = torch.stack([torch.matmul(matrix_inv.to(torch.float), pred[:,i].transpose(1,2)) \\n                            for i in range(3)], dim=1)\\n        pred = pred.transpose(2,3)[:,:,:,:2]\\n        pred = pred - centroid[:,None,:,:]\\n\\n    return loss, pred, confidences'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def forward(data, model, device, criterion = pytorch_neg_multi_log_likelihood_batch):\n",
    "    inputs = data[\"image\"].to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].to(device)\n",
    "    targets = data[\"target_positions\"].to(device)\n",
    "    matrix = data[\"world_to_image\"].to(device)\n",
    "    centroid = data[\"centroid\"].to(device)[:,None,:].to(torch.float)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    bs,tl,_ = targets.shape\n",
    "    assert tl == cfg[\"model_params\"][\"future_num_frames\"]\n",
    "\n",
    "    if cfg['train_params']['image_coords']:\n",
    "        targets = targets + centroid\n",
    "        targets = torch.cat([targets,torch.ones((bs,tl,1)).to(device)], dim=2)\n",
    "        targets = torch.matmul(matrix.to(torch.float), targets.transpose(1,2))\n",
    "        targets = targets.transpose(1,2)[:,:,:2]\n",
    "        bias = torch.tensor([56.25, 112.5])[None,None,:].to(device)\n",
    "        targets = targets - bias\n",
    "#     print(outputs)\n",
    "    confidences, pred = outputs[1], outputs[0]\n",
    "    pred = pred.view(bs, 3, tl, 2)\n",
    "    assert confidences.shape == (bs, 3)\n",
    "    confidences = torch.softmax(confidences, dim=1)\n",
    "\n",
    "    loss = criterion(targets, pred, confidences, target_availabilities)\n",
    "    loss = torch.mean(loss)\n",
    "\n",
    "    if cfg['train_params']['image_coords']:\n",
    "        matrix_inv = torch.inverse(matrix)\n",
    "        pred = pred + bias[:,None,:,:]\n",
    "        pred = torch.cat([pred,torch.ones((bs,3,tl,1)).to(device)], dim=3)\n",
    "        pred = torch.stack([torch.matmul(matrix_inv.to(torch.float), pred[:,i].transpose(1,2)) \n",
    "                            for i in range(3)], dim=1)\n",
    "        pred = pred.transpose(2,3)[:,:,:,:2]\n",
    "        pred = pred - centroid[:,None,:,:]\n",
    "\n",
    "    return loss, pred, confidences'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:28:59.315367Z",
     "iopub.status.busy": "2020-10-24T02:28:59.314461Z",
     "iopub.status.idle": "2020-10-24T02:29:10.914821Z",
     "shell.execute_reply": "2020-10-24T02:29:10.916062Z"
    },
    "id": "LU2qM364qRjA",
    "outputId": "5b7e4460-0a9b-41f7-d8ca-b0120bfccff1",
    "papermill": {
     "duration": 11.645752,
     "end_time": "2020-10-24T02:29:10.916236",
     "exception": false,
     "start_time": "2020-10-24T02:28:59.270484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting adamp\r\n",
      "  Downloading adamp-0.3.0.tar.gz (5.1 kB)\r\n",
      "Building wheels for collected packages: adamp\r\n",
      "  Building wheel for adamp (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5998 sha256=08878b6b4a19b7d06d4222bdf7b1cc6c8889b63648dad71696ed81054d9ab6dd\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/95/21/ced2d2cb9944e3a72e58fece7958973eed3fd8d0aeb6e2e450\r\n",
      "Successfully built adamp\r\n",
      "Installing collected packages: adamp\r\n",
      "Successfully installed adamp-0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install adamp\n",
    "from adamp import AdamP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:29:10.996966Z",
     "iopub.status.busy": "2020-10-24T02:29:10.996088Z",
     "iopub.status.idle": "2020-10-24T02:29:16.835907Z",
     "shell.execute_reply": "2020-10-24T02:29:16.836461Z"
    },
    "id": "myIsfSJmT-VN",
    "outputId": "7969e4c7-f32f-45cb-dd22-4e141338a303",
    "papermill": {
     "duration": 5.885741,
     "end_time": "2020-10-24T02:29:16.836620",
     "exception": false,
     "start_time": "2020-10-24T02:29:10.950879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ==== INIT MODEL=================\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LyftMultiModel('res2net50_14w_8s',cfg)\n",
    "# model1 = LyftMultiModel('res2net50_26w_4s',cfg)\n",
    "\n",
    "#load weight if there is a pretrained model\n",
    "weight_path = cfg[\"model_params\"][\"weight_path\"]\n",
    "\n",
    "model.to(device)\n",
    "# model1.to(device)\n",
    "\n",
    "optimizer = AdamP(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=1e-2)\n",
    "# optimizer1 = AdamP(model1.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=1e-2)\n",
    "print(f'device {device}')\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dataloader), eta_min=0.1)\n",
    "# scheduler1 = optim.lr_scheduler.CosineAnnealingLR(optimizer1, len(train_dataloader), eta_min=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:29:16.896436Z",
     "iopub.status.busy": "2020-10-24T02:29:16.895823Z",
     "iopub.status.idle": "2020-10-24T02:29:19.943787Z",
     "shell.execute_reply": "2020-10-24T02:29:19.942281Z"
    },
    "papermill": {
     "duration": 3.080731,
     "end_time": "2020-10-24T02:29:19.943914",
     "exception": false,
     "start_time": "2020-10-24T02:29:16.863183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if weight_path:\n",
    "    ckpt = torch.load(weight_path)\n",
    "    optimizer.load_state_dict(ckpt['res2net_16w_8s']['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(ckpt['res2net_16w_8s']['scheduler_state_dict'])\n",
    "#     optimizer1.load_state_dict(ckpt['res2net_26w_4s']['optimizer_state_dict'])\n",
    "#     scheduler1.load_state_dict(ckpt['res2net_26w_4s']['scheduler_state_dict'])\n",
    "    model.load_state_dict(ckpt['res2net_16w_8s']['model_state_dict'])\n",
    "#     model1.load_state_dict(ckpt['res2net_26w_4s']['model_state_dict'])\n",
    "    iterno = ckpt['iter']\n",
    "    del ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:29:20.021218Z",
     "iopub.status.busy": "2020-10-24T02:29:20.019885Z",
     "iopub.status.idle": "2020-10-24T02:30:14.135823Z",
     "shell.execute_reply": "2020-10-24T02:30:14.137791Z"
    },
    "id": "nze33wDSUD6y",
    "outputId": "5d4c4628-177d-479b-ca66-2149b8d256ee",
    "papermill": {
     "duration": 54.167281,
     "end_time": "2020-10-24T02:30:14.138057",
     "exception": false,
     "start_time": "2020-10-24T02:29:19.970776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 3410.59716796875 loss(avg): 3410.59716796875:   0%|          | 1/233340 [00:49<3228:47:31, 49.81s/it]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "confidences should sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2e0bcf72af9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#         loss1, _, _ = forward(data, model1, device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b642932b5f82>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(data, model, device, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_availabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-893219f9058b>\u001b[0m in \u001b[0;36mpytorch_neg_multi_log_likelihood_batch\u001b[0;34m(gt, pred, confidences, avails)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_modes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"expected 1D (Modes) array for gt, got {confidences.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfidences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"confidences should sum to 1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mavails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"expected 1D (Time) array for gt, got {avails.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# assert all data are valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: confidences should sum to 1"
     ]
    }
   ],
   "source": [
    "if cfg[\"model_params\"][\"train\"]:  \n",
    "    tr_it = iter(train_dataloader)\n",
    "    bf = 0\n",
    "    num_iter = cfg[\"train_params\"][\"max_num_steps\"]\n",
    "    losses_train = []\n",
    "    losses_train1 = []\n",
    "    iterations = []\n",
    "    metrics = []\n",
    "    times = []\n",
    "    model_name = cfg[\"model_params\"][\"model_name\"]\n",
    "    start = time.time()\n",
    "\n",
    "    progress_bar = tqdm(range(iterno,cfg[\"train_params\"][\"max_num_steps\"]))\n",
    "    for i in progress_bar:\n",
    "        try:\n",
    "            data = next(tr_it)\n",
    "        except StopIteration:\n",
    "            tr_it = iter(train_dataloader)\n",
    "            data = next(tr_it)\n",
    "        model.train()\n",
    "#         model1.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        loss, _, _ = forward(data, model, device)\n",
    "#         loss1, _, _ = forward(data, model1, device)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "#         optimizer1.zero_grad()\n",
    "#         loss1.backward()\n",
    "#         optimizer1.step()\n",
    "#         scheduler1.step()\n",
    "\n",
    "        losses_train.append(loss.item())\n",
    "#         losses_train1.append(loss1.item())\n",
    "\n",
    "        progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")\n",
    "#       :    loss: {loss1.item()} loss(avg): {np.mean(losses_train1)}\n",
    "        if i % cfg['train_params']['checkpoint_every_n_steps'] == 0:\n",
    "            torch.save({\n",
    "                        'res2net_16w_8s':{'model_state_dict':model.state_dict(),\n",
    "                                          'optimizer_state_dict':optimizer.state_dict(),\n",
    "                                          'scheduler_state_dict':scheduler.state_dict()},\n",
    "#                         'res2net_26w_4s':{'model_state_dict':model1.state_dict(),\n",
    "#                                           'scheduler_state_dict':scheduler1.state_dict(),\n",
    "#                                           'optimizer_state_dict':optimizer1.state_dict()},\n",
    "                        'iter':i+1}, f'./lyft_res2net_{i}.pth')\n",
    "            os.system(f'rm ./lyft_res2net_{bf}.pth')\n",
    "            bf = i\n",
    "            iterations.append(i)\n",
    "            metrics.append(np.mean(losses_train))\n",
    "            times.append((time.time()-start)/60)\n",
    "        if i % 5000 == 0 : \n",
    "            results = pd.DataFrame({'iterations': iterations, 'metrics (avg)': metrics, 'elapsed_time (mins)': times})\n",
    "            results.to_csv(f\"train_metrics_{model_name}_{num_iter}.csv\", index = False)\n",
    "            print(f\"Total training time is {(time.time()-start)/60} mins\")\n",
    "            print(results.head())\n",
    "            data = pd.DataFrame({'iter':list(range(len(losses_train))),'losses':losses_train})\n",
    "            sns.scatterplot(x = 'iter',y = 'losses',data = data,hue = 'losses')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:30:14.671469Z",
     "iopub.status.busy": "2020-10-24T02:30:14.659908Z",
     "iopub.status.idle": "2020-10-24T02:30:14.785535Z",
     "shell.execute_reply": "2020-10-24T02:30:14.787981Z"
    },
    "id": "Rmv-1hOS-o5Z",
    "papermill": {
     "duration": 0.398981,
     "end_time": "2020-10-24T02:30:14.788199",
     "exception": false,
     "start_time": "2020-10-24T02:30:14.389218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==== EVAL LOOP ================================================================\n",
    "if cfg[\"model_params\"][\"predict\"]:\n",
    "    \n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    # store information for evaluation\n",
    "    future_coords_offsets_pd = []\n",
    "    timestamps = []\n",
    "    confidences_list = []\n",
    "    agent_ids = []\n",
    "\n",
    "    progress_bar = tqdm(test_dataloader)\n",
    "    \n",
    "    for data in progress_bar:\n",
    "        inputs = data[\"image\"].to(device)\n",
    "        #target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "        target_availabilities = data[\"target_availabilities\"].to(device)\n",
    "        targets = data[\"target_positions\"].to(device)\n",
    "        matrix = data[\"world_to_image\"].to(device)\n",
    "        centroid = data[\"centroid\"].to(device)[:,None,:].to(torch.float)\n",
    "\n",
    "        bs,tl,_ = targets.shape\n",
    "        rs = cfg[\"raster_params\"][\"raster_size\"]\n",
    "        ec = cfg[\"raster_params\"][\"ego_center\"]\n",
    "        bias = torch.tensor([56.25, 112.5])[None, None, :].to(device)\n",
    "\n",
    "\n",
    "        #outputs = model(inputs).reshape(targets.shape)\n",
    "        pred, confidences = model(inputs)\n",
    "\n",
    "        if cfg['test_params']['image_coords']:\n",
    "            matrix_inv = torch.inverse(matrix)\n",
    "            pred = pred + bias[:,None,:,:]\n",
    "            pred = torch.cat([pred,torch.ones((bs,3,tl,1)).to(device)], dim=3)\n",
    "            pred = torch.stack([torch.matmul(matrix_inv.to(torch.float), pred[:,i].transpose(1,2)) \n",
    "                                for i in range(3)], dim=1)\n",
    "            pred = pred.transpose(2,3)[:,:,:,:2]\n",
    "            pred = pred - centroid[:,None,:,:]\n",
    "    \n",
    "        future_coords_offsets_pd.append(pred.cpu().numpy())\n",
    "        confidences_list.append(confidences.cpu().numpy())\n",
    "        timestamps.append(data[\"timestamp\"].numpy())\n",
    "        agent_ids.append(data[\"track_id\"].numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T02:30:15.363365Z",
     "iopub.status.busy": "2020-10-24T02:30:15.356299Z",
     "iopub.status.idle": "2020-10-24T02:30:17.032148Z",
     "shell.execute_reply": "2020-10-24T02:30:17.035172Z"
    },
    "id": "zMcDTPjO_DUT",
    "papermill": {
     "duration": 1.977586,
     "end_time": "2020-10-24T02:30:17.035660",
     "exception": false,
     "start_time": "2020-10-24T02:30:15.058074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timestamps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a017ea9d1485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m write_pred_csv(pred_path,\n\u001b[0;32m----> 4\u001b[0;31m            \u001b[0mtimestamps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m            \u001b[0mtrack_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m            \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_coords_offsets_pd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timestamps' is not defined"
     ]
    }
   ],
   "source": [
    "#create submission to submit to Kaggle\n",
    "pred_path = 'submission.csv'\n",
    "write_pred_csv(pred_path,\n",
    "           timestamps=np.concatenate(timestamps),\n",
    "           track_ids=np.concatenate(agent_ids),\n",
    "           coords=np.concatenate(future_coords_offsets_pd),\n",
    "           confs = np.concatenate(confidences_list)\n",
    "          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 188.8011,
   "end_time": "2020-10-24T02:30:19.584507",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-24T02:27:10.783407",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
